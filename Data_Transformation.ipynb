{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a181db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from decouple import config\n",
    "import requests\n",
    "import json\n",
    "from pathlib import Path\n",
    "from pymongo import MongoClient\n",
    "import pandas as pd\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from IPython.display import display, HTML\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import Process, Pool\n",
    "import multiprocessing \n",
    "from pymongo import UpdateOne, InsertOne\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from itertools import chain\n",
    "import re\n",
    "from datetime import datetime\n",
    "from scipy.stats.mstats import winsorize\n",
    "from scipy.stats import norm\n",
    "import warnings\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import KMeans\n",
    "from joblib import Parallel, delayed\n",
    "from sklearn import metrics\n",
    "from collections import defaultdict, Counter\n",
    "import itertools\n",
    "from deep_translator import GoogleTranslator\n",
    "import langdetect\n",
    "from difflib import SequenceMatcher\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.models import KeyedVectors\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "import matplotlib.cm as cm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2db593a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'false'\n"
     ]
    }
   ],
   "source": [
    "%%script false\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "00000dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to MongoDB\n",
    "client = MongoClient('mongodb://localhost:27017/')\n",
    "db = client['DM_Project']\n",
    "collection = db['Games_updated']\n",
    "df = pd.DataFrame(list(collection.find()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c85b518",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add 1 to 0 values and apply log\n",
    "def apply_log(Attr):\n",
    "    Attr = np.where(Attr == 0, Attr + 1, Attr)\n",
    "    #Apply log\n",
    "    return np.log(Attr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f59e0eb",
   "metadata": {},
   "source": [
    "# Winsorization of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff8eb014",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply Winsorization\n",
    "df['Net Votes'] = (winsorize(df['Net Votes'], limits=[0, 0.001]))\n",
    "df['Peak CCU'] = (winsorize(df['Peak CCU'], limits=[0, 0.001]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446a6b34",
   "metadata": {},
   "source": [
    "# Combining Genres and Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a81aef0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Turn string lists from kaggle dataset into arrays\n",
    "df['Genres'] = df['Genres'].apply(lambda x: x.split(', ') if isinstance(x, str) else x)\n",
    "df['Categories'] = df['Categories'].apply(lambda x: x.split(', ') if isinstance(x, str) else x)\n",
    "df['Genres'] = df['Genres'].apply(lambda x: x if isinstance(x, list) else [])\n",
    "#Combining Categories and Genres\n",
    "df['Combined Tags'] = df['Genres']+df['Categories']\n",
    "#Nan or 0.0 values into empty lists\n",
    "df['Combined Tags'] = df['Combined Tags'].apply(lambda x: x if isinstance(x, list) else [])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b34702",
   "metadata": {},
   "source": [
    "#### Replace separators with space in df tags "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5a484ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f997725d5074ef6b9e0f96917b35268",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Tags:   0%|          | 0/78774 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "combine_df = df.copy()\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas(desc=\"Processing Tags\")\n",
    "\n",
    "#Even with l=en in the API call some tags are in native language, Translate tags to english\n",
    "def translate_tags(tags):\n",
    "    translated_tags = []\n",
    "    for t in tags:\n",
    "        translated_text = GoogleTranslator(source='auto', target='en').translate(t)\n",
    "        #Single is translated to one for most languages, replace it\n",
    "        translated_text = translated_text.replace(\"one \",\"single \")\n",
    "        if translated_text not in translated_tags:\n",
    "            translated_tags.append(translated_text)\n",
    "    return translated_tags\n",
    "\n",
    "# Util to replace a character with space\n",
    "def remove_chars(s, rem):\n",
    "    for c in rem:\n",
    "        s = s.replace(c, \" \")\n",
    "    return s\n",
    "\n",
    "def process_tags(tags):\n",
    "    # Replace common separator with space\n",
    "    separate_tags = [t.replace('-', ' ').replace('/', ' ').lower() for t in tags]\n",
    "    # Some tags are still in string format separated by comma, separate them\n",
    "    no_comma_tags = []\n",
    "    for t in separate_tags:\n",
    "            if \",\" in t:\n",
    "                split_tags= t.split(',')\n",
    "                for st in split_tags:\n",
    "                        no_comma_tags.append(st)\n",
    "            else:\n",
    "                no_comma_tags.append(t)\n",
    "\n",
    "    \n",
    "    #Lowercase all tags\n",
    "    no_comma_tags = [t.lower() for t in no_comma_tags]\n",
    "    \n",
    "    #Remove special characters from tags\n",
    "    to_be_removed_char = [';', ':', '!', '*', '(',')','/']\n",
    "    no_special_tags = [remove_chars(t,to_be_removed_char) for t in no_comma_tags]\n",
    "    return no_special_tags\n",
    "\n",
    "combine_df['Genres'] = combine_df['Genres'].progress_apply(process_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf93b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get unique tags list\n",
    "unique_tags = set()\n",
    "for t in combine_df['Genres']:\n",
    "    unique_tags.update(t)\n",
    "unique_tags = list(unique_tags)\n",
    "\n",
    "tags_to_replace = {}\n",
    "\n",
    "#Even with l=en in the API call some tags are in native language, Translate unique tags to english\n",
    "for t in tqdm(unique_tags,desc = 'Translating tags'):\n",
    "        translated_text = GoogleTranslator(source='auto', target='en').translate(t)\n",
    "        #Single is translated to one for most languages, replace it\n",
    "        translated_text = translated_text.replace(\"one \",\"single \")\n",
    "        tags_to_replace[t] = translated_text\n",
    "        \n",
    "#Apply translations\n",
    "tqdm.pandas(desc=\"Processing Tags\")\n",
    "def replace_translation(tags):\n",
    "    translated=[]\n",
    "    for t in tags:\n",
    "        translated.append(tags_to_replace.get(t))\n",
    "    return translated\n",
    "combine_df['Genres'] = combine_df['Genres'].progress_apply(replace_translation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15baf5c4",
   "metadata": {},
   "source": [
    "#### Compute similarity between tags to remove duplicates or near duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd975f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_tags = {}\n",
    "def is_similar(a, b):\n",
    "    return SequenceMatcher(None, a, b).ratio() > 0.7\n",
    "\n",
    "for i,t1 in enumerate(unique_tags):\n",
    "    for j in range(i+1,len(unique_tags)):\n",
    "        if is_similar(t1, unique_tags[j]):\n",
    "            similar_tags[t1] = unique_tags[j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b31ef200",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cb0888cc8f14fe7a070289c7666f6a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Tags:   0%|          | 0/78774 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def replace_similar(tags):\n",
    "    replaced_tags = []\n",
    "    for t in tags:\n",
    "        if t in similar_tags:\n",
    "            replaced_tags.append(similar_tags.get(t))\n",
    "        else:\n",
    "            replaced_tags.append(t)\n",
    "    return replaced_tags\n",
    "combine_df['Genres'] = combine_df['Genres'].progress_apply(replace_similar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7129f193",
   "metadata": {},
   "source": [
    "#### Replace manually mistranslations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "73752354",
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_replace_dict={'physical education': 'fighting',\n",
    "                     'Strategy':'strategy',\n",
    "                     'fighters':'fighting',\n",
    "                     'role':'roleplaying',\n",
    "                     'racing games':'racing',\n",
    "                     'working with sound': 'audio production',\n",
    "                     'share':'shared screen',\n",
    "                     'massive multiplayer online mmo':'mmo',\n",
    "                     'strategic':'strategy',\n",
    "                     'Leisure':'hobby',\n",
    "                     'sexual content': 'mature content',\n",
    "                     'massively multiplayer online':'mmo',\n",
    "                     'episodic':'visual novel',\n",
    "                     'multiplayer games': 'multiplayer',\n",
    "                     'exposed':'mature content',\n",
    "                     'casual games':'casual',\n",
    "                     'aventura':'adventure',\n",
    "                     'adventure games':'adventure',\n",
    "                     'aktion':'action',\n",
    "                     'independent':'indie',\n",
    "                     'Sexual content':'mature content',\n",
    "                     'rpg role playing game':'role-playing games',\n",
    "                     'massive multiplayer':'mmo',\n",
    "                     'race':'racing',\n",
    "                     'strategie':'strategy',\n",
    "                     'recreational':'casual',\n",
    "                     'desporto':'sports',\n",
    "                     'independent producer':'indie',\n",
    "                     'rpg':'role-playing games',\n",
    "                     'role play':'role-playing games',\n",
    "                     'for free':'free to play',\n",
    "                     'strategies':'strategy',\n",
    "                     'massively multiplayer':'mmo' ,\n",
    "                     'estrategia':'strategy',\n",
    "                     'simulationen':'simulation',\n",
    "                     'ryo':'strategy'\n",
    "                    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bd72638a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef9bf1ae320f4e179c96d230bc1f92d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Tags:   0%|          | 0/78774 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def replace_manual(tags):\n",
    "    replaced_tags = []\n",
    "    for t in tags:\n",
    "        if t in manual_replace_dict:\n",
    "            replaced_tags.append(manual_replace_dict.get(t))\n",
    "        else:\n",
    "            replaced_tags.append(t)\n",
    "    return replaced_tags\n",
    "combine_df['Genres'] = combine_df['Genres'].progress_apply(replace_manual)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92709b6",
   "metadata": {},
   "source": [
    "#### Insert cleaned tags in mongodb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e7676431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'False'\n"
     ]
    }
   ],
   "source": [
    "%%script False\n",
    "collection = db['Clean_tags_games']\n",
    "\n",
    "# Convert df to list of dict and insert into MongoDB\n",
    "data_dict = combine_df.to_dict(\"records\")\n",
    "collection.insert_many(data_dict)\n",
    "\n",
    "print(\"Data inserted into MongoDB.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5251410e",
   "metadata": {},
   "source": [
    "#### Assign tags to cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6001052f",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = db['Clean_tags_games']\n",
    "tag_cluster_tf = pd.DataFrame(list(collection.find()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57182e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlb = MultiLabelBinarizer()\n",
    "genres_encoded = mlb.fit_transform(tag_cluster_tf['Genres'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b2422f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_columns = mlb.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b5d87da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a df from the one-hot encoded genres\n",
    "genres_df = pd.DataFrame(genres_encoded, columns=genre_columns)\n",
    "cluster_df = tag_cluster_tf.drop(['Genres','Categories','Combined Tags','_id', 'AppID', 'Name', 'Positive', 'Negative'],axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "782a5a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Min max normalization\n",
    "\n",
    "cluster_df['Peak CCU'] = (cluster_df['Peak CCU']-cluster_df['Peak CCU'].min())/(cluster_df['Peak CCU'].max()-cluster_df['Peak CCU'].min())\n",
    "cluster_df['Net Votes'] = (cluster_df['Net Votes']-cluster_df['Net Votes'].min())/(cluster_df['Net Votes'].max()-cluster_df['Net Votes'].min())\n",
    "# Concatenate the original DataFrame with the new one containing the one-hot encoded genres\n",
    "cluster_df = pd.concat([cluster_df, genres_df], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1783768e",
   "metadata": {},
   "source": [
    "#### Cluster word embedding - hopkins statistics for cluster tendency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "bc47721d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.999999988068642\n"
     ]
    }
   ],
   "source": [
    "def hopkins_statistic(X):\n",
    "    X_sample = shuffle(X, random_state=42)[:int(X.shape[0]/10)]  \n",
    "    nn = NearestNeighbors(n_neighbors=1).fit(X)\n",
    "    \n",
    "    # NN distances in the real dataset\n",
    "    real_distances, _ = nn.kneighbors(X_sample, return_distance=True)\n",
    "    real_distances_sum = np.sum(real_distances)\n",
    "    \n",
    "    #Simulated points with same variance of the dataset\n",
    "    random_points = np.random.uniform(np.min(X, axis=0), np.max(X, axis=0), X_sample.shape)\n",
    "    simulated_distances, _ = nn.kneighbors(random_points, return_distance=True)\n",
    "    simulated_distances_sum = np.sum(simulated_distances)\n",
    "    H = simulated_distances_sum / (real_distances_sum + simulated_distances_sum)\n",
    "    return H\n",
    "\n",
    "H = hopkins_statistic(tag_vectors)\n",
    "print(H)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
